# 파인튜닝

- 파인튜닝(Fine-tuning)은 사전 학습(Pre-trained)된 모델에 추가적인 지식(법률, 의료 등)을 학습시켜 도메인 전문가로 만드는 일입니다. 
- 도메인과 관련된 라벨링된 데이터와 인스트럭션 데이터로 구성된 데이터셋이 필요하여 데이터의 희소성이 높고, 기술적 환경도 요구되기 때문에 비용과 시간이 많이 소모될 수 있습니다.

> 파인튜닝은 기술적인 지식이 요구되는 작업이기 때문에 프롬프트 엔지니어링보다 더 어렵고 비전문가가 하기에는 진입장벽이 높습니다. 최근에는 LoRA, QLoRA, Prefix Tuning 등 PEFT(Parameter-Efficient Fine-Tuning) 기법이 등장해, 전체 모델을 모두 학습시키지 않고도 더 적은 리소스로 파인튜닝이 가능해졌습니다.

## vs 프롬프트 엔지니어링

| 항목 | Fine-tuning | Prompt Engineering |
| --- | --- | --- |
| 무엇을 바꾸나 | 모델 내부 | 입력 프롬프트 |
| 기술 필요 | 높음 (코딩, 학습 환경) | 낮음 (텍스트 설계 중심) |
| 비용/시간 | 높음 | 낮음 |
| 유연성 | 특정 도메인에 강함 | 다양한 상황에 빠르게 대응 |
| 활용 예 | 기업 전용 상담 모델 | 챗GPT 활용 자동화 문서 요약 |
| 적용 속도 | 느림 (훈련 필요) | 빠름 (즉시 적용 가능) |

## vs RAG

| 항목 | RAG(검색 증강 생성) | 파인튜닝(Fine-tuning) |
| --- | --- | --- |
| 방식 | 외부 지식을 실시간 검색하여 프롬프트에 주입 | 지식을 사전에 모델에 학습시켜 내장 |
| 적용 속도 | 빠름 (실시간 반영) | 느림 (학습/배포 필요) |
| 유연성 | 높음 (파일만 바꿔도 반영 가능) | 낮음 (매번 재학습 필요) |
| 유지보수 | 간단 (지식 DB만 관리) | 복잡 (모델/버전 관리 필요) |
| 적합 용도 | 자주 변하는 정보, 문서 기반 응답 | 고정된 업무, 정형화된 도메인 |
| 비용 | 낮음 (검색 비용만 발생) | 높음 (학습 비용, 인프라 필요) |
| 예시 | FAQ 챗봇, 문서 요약 | 기업 내부 QA 모델, 의료/법률 특화 AI |

## vs RAG vs 메모리

- RAG는 실시간 외부 지식 주입, 메모리는 사용자 성향 기억, 파인튜닝은 모델 내부 지식을 변경합니다.

| 항목 | RAG | 파인튜닝 | 메모리 |
| --- | --- | --- | --- |
| 목적 | 외부 지식 즉시 주입 | 모델 자체 학습 | 사용자 성향 기억 |
| 반영 시점 | 질의 직전 | 훈련 이후 | 대화 흐름 중 |
| 지속성 | 일회성 | 지속적 | 세션 간 유지 가능 |
| 구현 난이도 | 중간 (검색+연결) | 높음 (데이터+환경 필요) | 낮음 (설정만 하면 됨) |

## 역할 분담

- 파인튜닝은 교육 목표 설정 → 데이터 수집 → 데이터 정제 및 전처리 → 모델 구성 및 파인튜닝 → 평가 및 테스트 → 모델 배포 및 유지보수로 구성됩니다.
- 데이터 품질이 학습 효과를 좌우하므로, 데이터 수집·정제 단계가 특히 중요합니다.

| 단계 | 주요 작업 | 책임 주체 |
| --- | --- | --- |
| 목적 정의 | 모델이 어떤 업무를 대신할 것인지 정의- 어떤 데이터를 학습시킬지 목표 설정 | 기획자 / PM(혹은 도메인 전문가) |
| 데이터 수집 | 도메인 관련 문서, 상담 내역, QA 로그 등 수집- 개인정보, 중복 등 필터링 | 실무자 / 자료 담당자 |
| 데이터 정제 및 전처리 | 텍스트 정제, 라벨링, 토크나이징 대응- 포맷 통일, 구조화(JSON, CSV 등) | 데이터 엔지니어 / MLOps |
| 모델 구성 및 파인튜닝 실행 | 모델 선택, 학습 환경 설정- 파인튜닝 실행, 하이퍼파라미터 조정 | AI 개발자 / ML 엔지니어 |
| 평가 및 테스트 | 모델이 실제로 업무에 적합한지 확인- 테스트 케이스 기반으로 결과 검토 | 실무 사용자 / QA 팀 / 기획자 |
| 모델 배포 및 유지보수 |  모델 API 배포, 지속적 개선 필요 시 피드백 수집 | MLOps / 백엔드 개발자 |

## 정리

| 항목 | 설명 | 예시 |
| --- | --- | --- |
| 정의 | 사전 학습된 모델에 추가 데이터를 학습시켜 도메인 특화 모델을 만드는 방법 | 법률, 의료, 사내 QA 모델 구축 |
| 목적 | 특정 분야에서 더 정확한 답변 제공, 도메인 맞춤형 성능 향상 | 내부 상담 기록 학습 → 기업 전용 고객 응대 모델 |
| 필요한 준비 | 라벨링된 데이터셋, 학습 환경, 모델 구성 | 질문-답변 쌍, 데이터 정제, 토크나이징 |
| vs 프롬프트 엔지니어링 | 파인튜닝: 모델 내부 지식 변경 / 프롬프트 엔지니어링: 입력을 바꿔서 제어 | 파인튜닝은 느리지만 강력, 프롬프트는 빠르고 유연 |
| vs RAG | RAG: 검색 기반 실시간 정보 반영 / 파인튜닝: 지식 자체를 모델에 내장 | 자주 변하는 정책 → RAG, 고정된 전문 지식 → 파인튜닝 |
| vs 메모리 | 메모리: 사용자 성향 기억 / 파인튜닝: 지식 학습 | 파인튜닝: "법률 지식 내장", 메모리: "이 사람은 존댓말 선호" |
| 단계 | 목표 설정 → 데이터 수집·정제 → 파인튜닝 실행 → 평가·배포 | QA 로그 수집 → 정제 → 파인튜닝 → 테스트 → 운영 |

## 요약

- 파인튜닝은 모델 내부에 특정 지식이나 로직을 학습시켜, 도메인 특화 성능을 높이는 방법입니다.
- 프롬프트 엔지니어링이나 RAG보다 더 깊은 지식 내재화가 가능하지만, 비용과 시간이 많이 듭니다.
- 데이터 품질과 라벨링이 핵심이며, 학습 후에는 평가와 지속적인 유지보수가 필요합니다.

## 생각해보기

- 프롬프트 엔지니어링과 파인튜닝은 어떤 상황에서 각각 더 적합할까요?
- 파인튜닝과 RAG는 어떤 기준으로 선택해야 할까요?
- 파인튜닝을 할 때 '데이터 품질'이 중요한 이유는 무엇인가요?
- 파인튜닝 후 모델 평가를 어떻게 해야 할까요?
- 파인튜닝이 실패하거나 부작용을 일으킬 수 있는 경우는 어떤 경우인가요?
